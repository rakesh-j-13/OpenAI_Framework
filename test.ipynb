{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097b2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rakesh_jadhav\n"
     ]
    }
   ],
   "source": [
    "print(\"rakesh_jadhav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed1fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1840a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_DEFAULT_MODEL\"] = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566d5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a08fe",
   "metadata": {},
   "source": [
    "# Core Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65262db",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf349c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_0c297a60980ace070068e33f64b4f0819cb1eaac31c53add4b', created_at=1759723364.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0c297a60980ace070068e33f6521c0819c88e1e28d99ffa315', content=[ResponseOutputText(annotations=[], text='Crescent moon glimmers,  \\nSerpent wraps in cosmic grace,  \\nDance of stillness flows.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=14, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=23, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=37), user=None, billing={'payer': 'developer'}, store=True)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a haiku about Lord Shiva\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4462ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_08392325af8adad30068e2c17aff4c819eb2355addb8496ccf\",\n",
      "  \"created_at\": 1759691131.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_08392325af8adad30068e2c17b819c819e818d6de832c66cc9\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Dancing through the night,  \\nCrescent moon upon his brow,  \\nStillness in the storm.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 14,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 23,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 37\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2768c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(response):\n",
    "    print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e0440f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_08392325af8adad30068e2c17aff4c819eb2355addb8496ccf\",\n",
      "  \"created_at\": 1759691131.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_08392325af8adad30068e2c17b819c819e818d6de832c66cc9\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Dancing through the night,  \\nCrescent moon upon his brow,  \\nStillness in the storm.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 14,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 23,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 37\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "show(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29f3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CNWzNmlDsm24ZFqQv6VQV7FInCmL5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As the moonlight danced on the meadow, Luna, the gentle unicorn, spread her shimmering wings and soared through the starry sky, carrying dreams of magic and wonder to every child's pillow.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759724389, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=38, prompt_tokens=18, total_tokens=56, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "      }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fd3ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-CNWzNmlDsm24ZFqQv6VQV7FInCmL5\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"As the moonlight danced on the meadow, Luna, the gentle unicorn, spread her shimmering wings and soared through the starry sky, carrying dreams of magic and wonder to every child's pillow.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1759724389,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_560af6e559\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 38,\n",
      "    \"prompt_tokens\": 18,\n",
      "    \"total_tokens\": 56,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "show(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b4a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_05251642b01ee65c0068e344c0af148193b55e6c0bcc329034\",\n",
      "  \"created_at\": 1759724736.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_05251642b01ee65c0068e344c152408193be10b034d3bd520f\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_05251642b01ee65c0068e344c6dbd48193bb364eb15aa0916b\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Aye, they be mostly optional, but not always, matey. JavaScript has Automatic Semicolon Insertion (ASI), which drops semicolons fer ye at many line breaks. But there be reefs ye can run aground on.\\n\\nWatch out for these gotchas:\\n- After return, throw, break, continue, yield: a newline ends the statement. Any expression on the next line gets ignored. Example: return\\n  { ok: true } // returns undefined, arr!\\n- Lines that start with (, [, +, -, /, or a template tag: they might be parsed as a continuation of the previous line. Example pitfalls:\\n  - a = b + c\\n    (function(){})() // looks like calling the result of a = b + c\\n  - foo\\n    /bar/.test(x) // might be seen as division\\n- ++ and -- across lines can bind to the wrong side if ye split lines unwisely.\\n\\nWays to sail safe:\\n- Either always use semicolons, or use none but start any “risky” line with a leading semicolon:\\n  ;(function(){})()\\n  ;[1,2].forEach(...)\\n- Don’t put expressions on the line after return/throw/break/continue/yield.\\n- Let a formatter steer the ship. Prettier’s default keeps semicolons; if ye prefer none, set semi: false and it’ll insert the guard semicolons where needed.\\n\\nIn short: optional by rule o’ ASI, but required in spirit to avoid these edge cases. Pick a style, be consistent, and mind the sharp rocks.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"low\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 24,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 661,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 320\n",
      "    },\n",
      "    \"total_tokens\": 685\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"Talk like a pirate.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "show(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd7571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_0dcb9bf54a570cbd0068e3453e8798819fb86a296b96cfff37\",\n",
      "  \"created_at\": 1759724862.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"Talk like a pirate.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_0dcb9bf54a570cbd0068e3453ecff0819fa5a6844f25a3e299\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_0dcb9bf54a570cbd0068e345458c8c819fbca65c7c1f6a6a27\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Aye, mostly optional, matey—but mind the reefs!\\n\\n- JavaScript has automatic semicolon insertion (ASI), so many lines don’t need ye to type ’em.\\n- Ye still need semicolons:\\n  - In for(;;) loop headers.\\n  - To put multiple statements on one line.\\n  - At the start of a line when ye begin with ( or [ (e.g., IIFEs or array literals) to avoid gluin’ it to the line above: ;(function(){})()\\n- ASI can betray ye after certain keywords if ye put a newline:\\n  - return\\n  - throw\\n  - break / continue\\n  - yield (in generators)\\n  Putting the value on the next line makes ASI insert a semicolon right after the keyword—arrr, that’s a bug.\\n\\n- Other gotchas:\\n  - a\\n    ++b or a\\n    --b can misbehave; keep operators with their operands.\\n  - new on one line and the constructor on the next changes what gets constructed.\\n\\nBest practice, ye scallywag: pick a style and be consistent. Many crews either always use semicolons, or always omit ’em and add a leading semicolon before lines starting with ( or [. Tools like Prettier can keep yer code shipshape.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"low\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 24,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 725,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 448\n",
      "    },\n",
      "    \"total_tokens\": 749\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    instructions=\"Talk like a pirate.\",\n",
    "    input=\"Are semicolons optional in JavaScript?\",\n",
    ")\n",
    "\n",
    "show(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba54bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
